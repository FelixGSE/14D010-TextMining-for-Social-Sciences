{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.99104426988e-11\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "r = np.random.beta(0.1, 1)\n",
    "print r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I was offered a beer the other day that was reportedly made with citra hops. What are citra hops? Why should I care that my beer is made with them?', 'As far as we know, when did humans first brew beer, and where? Around when would you have been able to get your hands on something resembling a modern lager?', \"How is low/no alcohol beer made? I'm assuming that the beer is made normally and the alcohol is then removed, is it any more than just boiling it off? I've noticed that no/low alcohol beers' taste improved hugely a few years ago, is this due to a new technique?\", \"In general, what's the best way to work out the temperature at which to serve a particular beer? Room temperature? Cold? Supercold? Warm?\", \"Assuming we're comparing equivalent amounts of alcohol, do certain beers get you inebriated more quickly or slowly? Does the amount of fizz make a difference?\", 'Apart from coming out of different taps, some ales seem very similar to lagers (although there are clearly a much greater variety of ales). Is there a difference in the way they are made?', \"It's pretty cold at the moment. Mulled wine being more of a Christmas drink, mulled beer is getting popular. What beers, and what spices should I use to make it?\", 'Beer varies widely, and one of the most noticeable differences when drinking is the carbonation level.  What factors in the composition, brewing process, storage, etc affect the final level of carbonation? ', 'Ales and lagers are brewed with different types of yeast.  Ale yeast ferments at the top of the brewing vat at a comfortable room temperature while lager yeast ferments at the bottom of the vat at a lower temperature.  The \"low and slow\" lager fermentation brings out more complex flavors.', \"It all depends on the beer really. Lagers are typically brewed longer than ales. Of the few brews I've made so far, I usually let them ferment for 2 weeks in the fermenter, then I bottle them and wait another 2 weeks.\"]\n"
     ]
    }
   ],
   "source": [
    "from xml.etree import cElementTree as ET\n",
    "import sys\n",
    "\n",
    "posts = open('Posts.xml', 'r').read()\n",
    "\n",
    "posts[1:100]\n",
    "\n",
    "def remove_tags(text):\n",
    "    return ''.join(ET.fromstring(text).itertext())\n",
    "\n",
    "root = ET.fromstring(posts)\n",
    "documents = []\n",
    "for child in root.findall('row')[0:200]:\n",
    "    text = None\n",
    "    try:\n",
    "        child_text = child.get('Body').encode('utf-8').strip()\n",
    "        text = remove_tags(child_text)\n",
    "    except ET.ParseError as e:\n",
    "        #print(\"Caught exception: \" + str(e))\n",
    "        \"Caught exception: \" + str(e)\n",
    "    if text != None: documents.append(text)\n",
    "        \n",
    "    \n",
    "print documents[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'wa' u'offer' u'beer' u'the' u'day' u'wa' u'reportedli' u'citra' u'hop'\n",
      " u'are' u'citra' u'hop' u'whi' u'care' u'beer']\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "execfile('corpus.py')\n",
    "execfile('document.py')\n",
    "\n",
    "corpus = Corpus(documents, '../Week1HW/stopwords.txt', 3)\n",
    "\n",
    "print corpus.docs[0].tokens\n",
    "# FIXME: Not sure why this is not 100\n",
    "print corpus.N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term: skunk\n",
      "Original topic distribution: [ 0.  7.  1.]\n",
      "Term: can\n",
      "Original topic distribution: [ 6.  3.  7.]\n",
      "Term: wine\n",
      "Original topic distribution: [ 0.  2.  3.]\n",
      "Term: saison\n",
      "Original topic distribution: [ 0.  1.  3.]\n",
      "Iteration 0\n",
      "[ 0.44160843  0.24262541  0.31576616]\n",
      "[ 0.00241498  0.          0.00109603]\n",
      "[ 0.          0.          0.00135199]\n",
      "[ 0.05230083  0.0298082   0.03281211]\n",
      "[ 0.05411699  0.05754022  0.07095561]\n",
      "[ 0.          0.00094788  0.        ]\n",
      "[ 0.00241498  0.          0.00109603]\n",
      "[ 0.00110351  0.          0.        ]\n",
      "[ 0.          0.          0.00252525]\n",
      "[ 0.0013333   0.00246695  0.00968868]\n",
      "[ 0.01253634  0.00570346  0.0400965 ]\n",
      "[ 0.          0.          0.00252525]\n",
      "[ 0.0013333   0.00246695  0.00968868]\n",
      "[ 0.00960969  0.00358822  0.00498768]\n",
      "[ 0.00132675  0.00015784  0.        ]\n",
      "[ 0.05230083  0.0298082   0.03281211]\n",
      "Term: skunk\n",
      "New topic distribution: [ 0.  8.  0.]\n",
      "Term: can\n",
      "New topic distribution: [  6.   0.  10.]\n",
      "Term: wine\n",
      "New topic distribution: [ 0.  0.  5.]\n",
      "Term: saison\n",
      "New topic distribution: [ 0.  0.  4.]\n"
     ]
    }
   ],
   "source": [
    "# Initizations\n",
    "#\n",
    "D = len(corpus.docs)\n",
    "K = 3 # K - numer of topics\n",
    "V = len(corpus.token_set)\n",
    "\n",
    "# Randomly assign each word in each document to a topic\n",
    "# each array is of \"arbitrary\" length - length of document's respective word list\n",
    "word_topic_assignments = [[]]*corpus.N\n",
    "for doci, doc in enumerate(corpus.docs):\n",
    "    word_topic_assignments[doci] = []\n",
    "    for wordi, word in enumerate(doc.tokens):\n",
    "        word_topic_assignments[doci].append(np.random.randint(0,K))\n",
    "\n",
    "#print word_topic_assignments[0]\n",
    "\n",
    "# Initialize document counts of words for each topic, D x K\n",
    "document_topic_word_distribution = np.zeros((D, K))\n",
    "for doci, doc in enumerate(corpus.docs):\n",
    "    # sum the number of words in topic k\n",
    "    for k in range(0,K):\n",
    "        document_topic_word_distribution.itemset((doci, k), word_topic_assignments[doci].count(k))\n",
    "\n",
    "#print document_topic_word_distribution[0,:]\n",
    "\n",
    "# Initialize term topic counts, e.g. number of times term V was allocated to topic K, K x V\n",
    "# For every word in every document, determine what it's term index is\n",
    "topic_term_distribution = np.zeros((K, V))\n",
    "termlist = list(corpus.token_set)\n",
    "for doci, doc in enumerate(corpus.docs):\n",
    "    for wordi, word in enumerate(doc.tokens):\n",
    "        termidx = termlist.index(word)\n",
    "        topic_alloc = word_topic_assignments[doci][wordi]\n",
    "        current_count = topic_term_distribution.item((topic_alloc,termidx))\n",
    "        topic_term_distribution.itemset((topic_alloc,termidx), current_count + 1)\n",
    "        \n",
    "#print topic_term_distribution[0,:][0:10]\n",
    "\n",
    "alpha = 50/K\n",
    "eta = 200/V\n",
    "\n",
    "# Initialize theta - document-specific topic probabilities\n",
    "theta = np.zeros((D, K))\n",
    "# draw theta - Dirichlet with paramters (alpha + n_{d,k}) - num of words in doc with topic alloc k\n",
    "for doci in range(D):\n",
    "    theta_params = alpha + document_topic_word_distribution[doci,:]\n",
    "    # theta for this document\n",
    "    theta_d = np.random.dirichlet(tuple(theta_params), 1)\n",
    "    theta[doci,:] = theta_d\n",
    "\n",
    "# Initialize beta - topic-specific term probabilities\n",
    "beta = np.zeros((K, V))\n",
    "# draw beta - Dirichlet with paramters (eta + m_{k,v}) - num of times term appeared in topic k\n",
    "for k in range(K):\n",
    "    beta_params = eta + topic_term_distribution[k,:]\n",
    "    beta_k = np.random.dirichlet(tuple(beta_params), 1)\n",
    "    beta[k,:] = beta_k\n",
    "    \n",
    "terms_to_sanity_check = ['skunk', 'can', 'wine', 'saison']\n",
    "for term in terms_to_sanity_check:\n",
    "    termidx = termlist.index(term)    \n",
    "    print 'Term: ' + term\n",
    "    print 'Original topic distribution: ' + str(topic_term_distribution[:,termidx])\n",
    "\n",
    "iters = 10\n",
    "for i in range(iters):\n",
    "    if i%25 == 0: print 'Iteration ' + str(i)\n",
    "    # 1 iteration\n",
    "    for doci, doc in enumerate(corpus.docs):\n",
    "        theta_d = theta[doci,:]\n",
    "        if i == 0 and doci == 0: print theta_d\n",
    "        for wordi, word in enumerate(doc.tokens):\n",
    "            word_topic_alloc = word_topic_assignments[doci][wordi]\n",
    "            termidx = termlist.index(word)\n",
    "            beta_v = beta[:,termidx]\n",
    "            if i == 0 and doci == 0: print beta_v            \n",
    "            # decrement counts\n",
    "            current_doc_count = document_topic_word_distribution.item((doci, word_topic_alloc))\n",
    "            document_topic_word_distribution.itemset((doci, word_topic_alloc), current_doc_count - 1)\n",
    "            current_topic_count = topic_term_distribution.item((word_topic_alloc, termidx))\n",
    "            topic_term_distribution.itemset((word_topic_alloc, termidx), current_topic_count - 1)\n",
    "            probs = theta_d*beta_v/np.sum(theta_d*beta_v)\n",
    "            new_topic_alloc = np.random.multinomial(1, tuple(probs))\n",
    "            new_topic_alloc = list(new_topic_alloc).index(1)                \n",
    "            word_topic_assignments[doci][wordi] = new_topic_alloc\n",
    "            # increment counts\n",
    "            current_doc_count = document_topic_word_distribution.item((doci, new_topic_alloc))\n",
    "            document_topic_word_distribution.itemset((doci, new_topic_alloc), current_doc_count + 1)\n",
    "            current_topic_count = topic_term_distribution.item((new_topic_alloc, termidx))\n",
    "            topic_term_distribution.itemset((new_topic_alloc, termidx), current_topic_count + 1) \n",
    "    # update theta\n",
    "    for doci in range(D):\n",
    "        theta_params = alpha + document_topic_word_distribution[doci,:]\n",
    "        # theta for this document\n",
    "        theta_d = np.random.dirichlet(tuple(theta_params), 1)\n",
    "        theta[doci,:] = theta_d\n",
    "    for k in range(K):\n",
    "        beta_params = eta + topic_term_distribution[k,:]\n",
    "        beta_k = np.random.dirichlet(tuple(beta_params), 1)\n",
    "        beta[k,:] = beta_k    \n",
    "        \n",
    "for termi, term in enumerate(terms_to_sanity_check):\n",
    "    termidx = termlist.index(term)\n",
    "    print 'Term: ' + term\n",
    "    print 'New topic distribution: ' + str(topic_term_distribution[:,termidx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
